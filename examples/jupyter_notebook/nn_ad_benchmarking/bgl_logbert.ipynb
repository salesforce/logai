{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Anomaly Detection on BGL dataset using LogBERT model\n",
    "This is a running example of an end-to-end workflow of Log Anomaly Detection on public dataset HDFS using the LogBERT model.\n",
    "\n",
    "There are similar workflows on the BGL datasets using other anomaly detectors (like LSTM based one in `bgl_lstm_unsupervised_parsed_sequential.ipynb`). \n",
    "\n",
    "The actual workflow script is exactly identical in these cases, except in the LogBERT case we choose to skip the log-parsing step. This is simply done following past literature, but there are no restrictions from the LogAI library side. \n",
    "\n",
    "\n",
    "Also check out the other config files that in this directory that cater to other datasets (HDFS), or other experimental configs like (parsing/nonparsing based, sliding/session window based log partitioning, sequential/semantic log feature representations, supervised/unsupervised setting, LSTM/CNN/Transformer/BERT model). \n",
    "\n",
    "To use these different experimental configs, you only need to point to the correct config file and the same workflow code should work perfectly for those!\n",
    "\n",
    "Only in case of changing the dataset (eg. from BGL to HDFS) you need to not only change the config.yaml file but also use the HDFSPreprocessor in the preprocessing step. Note that each custom dataset that are added should have its own Preprocessor class (which should inherit from logai.preproces.preprocessor.Preprocessor). \n",
    "\n",
    "For more complete explanations of each step of the workflow check out the `hdfs_lstm_unsupervised_parsed_sequential.ipynb` notebook instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from logai.applications.openset.anomaly_detection.openset_anomaly_detection_workflow import OpenSetADWorkflowConfig, validate_config_dict\n",
    "from logai.utils.file_utils import read_file\n",
    "from logai.utils.dataset_utils import split_train_dev_test_for_anomaly_detection\n",
    "import logging \n",
    "from logai.dataloader.data_loader import FileDataLoader\n",
    "from logai.preprocess.bgl_preprocessor import BGLPreprocessor\n",
    "from logai.information_extraction.log_parser import LogParser\n",
    "from logai.preprocess.openset_partitioner import OpenSetPartitioner\n",
    "from logai.analysis.nn_anomaly_detector import NNAnomalyDetector\n",
    "from logai.information_extraction.log_vectorizer import LogVectorizer\n",
    "from logai.utils import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/bgl_logbert_config.yaml\"\n",
    "config_parsed = read_file(config_path)\n",
    "config_dict = config_parsed[\"workflow_config\"]\n",
    "config = OpenSetADWorkflowConfig.from_dict(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         RAS KERNEL INFO instruction cache parity error...\n",
      "1         RAS KERNEL INFO instruction cache parity error...\n",
      "2         RAS KERNEL INFO instruction cache parity error...\n",
      "3         RAS KERNEL INFO instruction cache parity error...\n",
      "4         RAS KERNEL INFO instruction cache parity error...\n",
      "                                ...                        \n",
      "358455    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358456    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358457    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358458    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358459    RAS KERNEL FATAL idoproxy communication failur...\n",
      "Name: logline, Length: 358460, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amrita.saha/opt/anaconda3/envs/loglib/lib/python3.8/site-packages/logai/dataloader/data_loader.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected[constants.LOG_TIMESTAMPS] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "dataloader = FileDataLoader(config.data_loader_config)\n",
    "logrecord = dataloader.load_data()\n",
    "print (logrecord.body[constants.LOGLINE_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         RAS KERNEL INFO instruction cache parity error...\n",
      "1         RAS KERNEL INFO instruction cache parity error...\n",
      "2         RAS KERNEL INFO instruction cache parity error...\n",
      "3         RAS KERNEL INFO instruction cache parity error...\n",
      "4         RAS KERNEL INFO instruction cache parity error...\n",
      "                                ...                        \n",
      "358455    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358456    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358457    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358458    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358459    RAS KERNEL FATAL idoproxy communication failur...\n",
      "Name: logline, Length: 358460, dtype: object\n"
     ]
    }
   ],
   "source": [
    "preprocessor = BGLPreprocessor(config.preprocessor_config)\n",
    "preprocessed_filepath = os.path.join(config.output_dir, 'BGL_11k_processed.csv')            \n",
    "logrecord = preprocessor.clean_log(logrecord)\n",
    "logrecord.save_to_csv(preprocessed_filepath)\n",
    "print (logrecord.body[constants.LOGLINE_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       RAS KERNEL INFO instruction cache parity error...\n",
      "1       RAS KERNEL INFO instruction cache parity error...\n",
      "2       RAS KERNEL INFO instruction cache parity error...\n",
      "3       RAS KERNEL INFO instruction cache parity error...\n",
      "4       RAS KERNEL INFO instruction cache parity error...\n",
      "                              ...                        \n",
      "1848    RAS APP FATAL ciod Error reading message prefi...\n",
      "1849    RAS KERNEL FATAL Lustre mount FAILED ALPHANUM ...\n",
      "1850    RAS KERNEL FATAL Lustre mount FAILED ALPHANUM ...\n",
      "1851    RAS KERNEL FATAL Lustre mount FAILED ALPHANUM ...\n",
      "1852    RAS KERNEL FATAL idoproxy communication failur...\n",
      "Name: logline, Length: 1853, dtype: object\n"
     ]
    }
   ],
   "source": [
    "partitioner = OpenSetPartitioner(config.open_set_partitioner_config)\n",
    "partitioned_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session.csv')\n",
    "logrecord = partitioner.partition(logrecord)\n",
    "logrecord.save_to_csv(partitioned_filepath)\n",
    "print (logrecord.body[constants.LOGLINE_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices_train/dev/test:  32 4 1817\n",
      "Train/Dev/Test Anomalous 0 0 1808\n",
      "Train/Dev/Test Normal 32 4 9\n"
     ]
    }
   ],
   "source": [
    "train_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session_unsupervised_train.csv')\n",
    "dev_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session_unsupervised_dev.csv')\n",
    "test_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session_unsupervised_test.csv')\n",
    "\n",
    "(train_data, dev_data, test_data) = split_train_dev_test_for_anomaly_detection(\n",
    "                logrecord,training_type=config.training_type,\n",
    "                test_data_frac_neg_class=config.test_data_frac_neg,\n",
    "                test_data_frac_pos_class=config.test_data_frac_pos,\n",
    "                shuffle=config.train_test_shuffle\n",
    "            )\n",
    "\n",
    "train_data.save_to_csv(train_filepath)\n",
    "dev_data.save_to_csv(dev_filepath)\n",
    "test_data.save_to_csv(test_filepath)\n",
    "print ('Train/Dev/Test Anomalous', len(train_data.labels[train_data.labels[constants.LABELS]==1]), \n",
    "                                   len(dev_data.labels[dev_data.labels[constants.LABELS]==1]), \n",
    "                                   len(test_data.labels[test_data.labels[constants.LABELS]==1]))\n",
    "print ('Train/Dev/Test Normal', len(train_data.labels[train_data.labels[constants.LABELS]==0]), \n",
    "                                   len(dev_data.labels[dev_data.labels[constants.LABELS]==0]), \n",
    "                                   len(test_data.labels[test_data.labels[constants.LABELS]==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e97ece68d6c4913879fb3166db107d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa2716db10044cebec9aca7bcf7cd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99dbcea60be4d28a4b21272326c6e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7809d91bc8af48b8b6bd4e86283c23d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6552b9e2e6fa4ab1b17a9762c62894d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5937203ca984ebfbd056bebbba35c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dc7f96811346599318fa66f6e3ba48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8359399ca143e49a7cf517350c2d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4402563955ef426c8274a8b3eea56d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b265d40ce7c1413585279aeb1599cb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cdce1a0e644cbb8201daaf47d8fccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbac6cff790a4641a9ca6f730f0aa7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 32\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "vectorizer = LogVectorizer(config.log_vectorizer_config)\n",
    "vectorizer.fit(train_data)\n",
    "train_features = vectorizer.transform(train_data)\n",
    "dev_features = vectorizer.transform(dev_data)\n",
    "test_features = vectorizer.transform(test_data)\n",
    "print (train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized data collator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/Users/amrita.saha/opt/anaconda3/envs/loglib/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 32\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 80\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 03:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.347700</td>\n",
       "      <td>7.127536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50\n",
      "Configuration saved in temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50/config.json\n",
      "Model weights saved in temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anomaly_detector = NNAnomalyDetector(config=config.nn_anomaly_detection_config)\n",
    "anomaly_detector.fit(train_features, dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading model from /Users/amrita.saha/Home/salesforce/workspace/code/AIOps/RCA_Log/logai_opensource/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-100\n",
      "loading configuration file /Users/amrita.saha/Home/salesforce/workspace/code/AIOps/RCA_Log/logai_opensource/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-100/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 332\n",
      "}\n",
      "\n",
      "loading weights file /Users/amrita.saha/Home/salesforce/workspace/code/AIOps/RCA_Log/logai_opensource/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-100/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at /Users/amrita.saha/Home/salesforce/workspace/code/AIOps/RCA_Log/logai_opensource/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f10c5ae5064807959f208577fb52e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1817 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1858\n",
      "  Batch size = 256\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.884676456451416 test_runtime: 380.0454 test_samples/s: 4.889\n",
      "INFO:root:number of original test instances 1469\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.9087990307260405, std: 0.7953828009166797\n",
      "INFO:root:loss_mean Neg scores: mean: 3.618975732840743, std: 1.6822439832876217\n",
      "INFO:root:AUC of loss_mean: 0.9352159468438538\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.483360423272025, std: 0.3953119902978529\n",
      "INFO:root:loss_max Neg scores: mean: 4.501153945922852, std: 2.1830750224544437\n",
      "INFO:root:AUC of loss_max: 0.9408833300762166\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.648272041080209, std: 0.5242323353348409\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.905489637738182, std: 1.8918413511898604\n",
      "INFO:root:AUC of loss_top6_mean: 0.9711745163181551\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8799302817190238, std: 0.003586756438542158\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.8638905097863503, std: 0.012238458913726076\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.8035958569474301\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 2.1201639449112606, std: 0.030311899499368054\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 1.9984799112592424, std: 0.09129906432881922\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.80281414891538\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.8350373132148396, std: 0.04774834221800779\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.2409814454260326, std: 0.5494119653290934\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.6985538401407074\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1858\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.8940958976745605 test_runtime: 391.2892 test_samples/s: 4.748\n",
      "INFO:root:number of original test instances 1521\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1858\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.845270156860352 test_runtime: 386.8702 test_samples/s: 4.803\n",
      "INFO:root:number of original test instances 1578\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.907718217158561, std: 0.4043983715316972\n",
      "INFO:root:loss_mean Neg scores: mean: 3.382695775026246, std: 1.0991956194923773\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.707508697631253, std: 0.3208316680386524\n",
      "INFO:root:loss_max Neg scores: mean: 4.9436929523944855, std: 2.270872183178602\n",
      "INFO:root:AUC of loss_max: 0.9746019108280255\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.658333589694049, std: 0.26375133667216016\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.7447068177991443, std: 1.3644584454599087\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8797631816321065, std: 0.0034920250748031135\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.8662098156960889, std: 0.01312254897278986\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.7245222929936306\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 2.118752788414115, std: 0.029501734933459377\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 2.016391462129023, std: 0.09860014895925796\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.7246019108280255\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.8378975549076606, std: 0.047168752059200965\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.308915948288308, std: 0.5423242176110548\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.7433121019108281\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1858\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.902355194091797 test_runtime: 382.4702 test_samples/s: 4.858\n",
      "INFO:root:number of original test instances 1640\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1858\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.868999004364014 test_runtime: 383.3589 test_samples/s: 4.847\n",
      "INFO:root:number of original test instances 1683\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.920148221309522, std: 0.3566757207660673\n",
      "INFO:root:loss_mean Neg scores: mean: 3.2478738335926436, std: 0.9785259340926624\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.756247967392651, std: 0.3020146397331471\n",
      "INFO:root:loss_max Neg scores: mean: 4.94701823592186, std: 2.270355316893744\n",
      "INFO:root:AUC of loss_max: 0.9816417910447761\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.710901800642362, std: 0.24537859594446257\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.5826374517546755, std: 1.2310723233439638\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8796587121719942, std: 0.0034385457377637844\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.8664167847406741, std: 0.013133275510927451\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.7051492537313433\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 2.1178713350137865, std: 0.029057285990425043\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 2.017975316031112, std: 0.09888953314848281\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.7051492537313433\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.840473497074832, std: 0.04626868512520104\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.309191839396954, std: 0.5410503941654905\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.7498507462686567\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1858\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.907938003540039 test_runtime: 394.4318 test_samples/s: 4.711\n",
      "INFO:root:number of original test instances 1731\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1857\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.864945888519287 test_runtime: 393.193 test_samples/s: 4.723\n",
      "INFO:root:number of original test instances 1762\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.929079766560031, std: 0.33463519180139617\n",
      "INFO:root:loss_mean Neg scores: mean: 3.1887111990196586, std: 0.9732760917406157\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.78076688376093, std: 0.2998567894493911\n",
      "INFO:root:loss_max Neg scores: mean: 5.17869359254837, std: 2.5063636922181893\n",
      "INFO:root:AUC of loss_max: 0.967502850627138\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.763326366827785, std: 0.2483408765544348\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.5923239290714264, std: 1.2769347057849996\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8796277117918756, std: 0.0034515691720516223\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.8665742223383859, std: 0.013015930285878012\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.6992588369441277\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 2.1176190027840374, std: 0.029190893011465234\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 2.019084519810147, std: 0.09811704259831583\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.6992588369441277\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.842915362938266, std: 0.04508518161105077\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.311091010769208, std: 0.5402702079295059\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.7549885974914482\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1857\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.903265953063965 test_runtime: 384.7599 test_samples/s: 4.826\n",
      "INFO:root:number of original test instances 1803\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1857\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.851230144500732 test_runtime: 381.9937 test_samples/s: 4.861\n",
      "INFO:root:number of original test instances 1816\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.932833810220314, std: 0.31970477373520695\n",
      "INFO:root:loss_mean Neg scores: mean: 3.1603801690085693, std: 0.9341407161133001\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.807894197959035, std: 0.2937742492019078\n",
      "INFO:root:loss_max Neg scores: mean: 5.257125748528375, std: 2.4196701242926126\n",
      "INFO:root:AUC of loss_max: 0.9444751890795057\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.7535741145295765, std: 0.2687491083267956\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.5896224975585938, std: 1.24861338300561\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8796215265727366, std: 0.0034751428831847975\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.8678981571308808, std: 0.012591848174185542\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.6969193875668696\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 2.117574454755762, std: 0.0294118048906709\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 2.0287753255278975, std: 0.09486351947639016\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.6975342802680932\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.8446500399503685, std: 0.04425995347564116\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.376224127816565, std: 0.5411800705198854\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.6805632417143208\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1857\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.874952793121338 test_runtime: 378.4836 test_samples/s: 4.906\n",
      "INFO:root:number of original test instances 1817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      indices  max_loss   sum_loss num_loss  \\\n",
      "0           0  2.477225  19.516182        9   \n",
      "1           0  2.496417  17.288784        8   \n",
      "2           1  2.511517  17.309793        8   \n",
      "3           2  8.343674  60.673038        9   \n",
      "4           3  2.544247     17.348        8   \n",
      "...       ...       ...        ...      ...   \n",
      "18571    1813   8.47681  52.004642        8   \n",
      "18572    1814   8.77824  55.250885        9   \n",
      "18573    1815  8.773056  55.483009        9   \n",
      "18574    1815  8.790743   47.12072        8   \n",
      "18575    1816  9.254669  64.524132        8   \n",
      "\n",
      "                                               top6_loss  \\\n",
      "0      [2.477224826812744, 2.36291241645813, 2.281082...   \n",
      "1      [2.4964170455932617, 2.313321113586426, 2.2107...   \n",
      "2      [2.511516571044922, 2.361931324005127, 2.20818...   \n",
      "3      [8.343673706054688, 7.839829921722412, 7.30509...   \n",
      "4      [2.5442466735839844, 2.326444625854492, 2.2223...   \n",
      "...                                                  ...   \n",
      "18571  [8.476810455322266, 7.880990982055664, 7.82718...   \n",
      "18572  [8.778240203857422, 8.005950927734375, 7.82399...   \n",
      "18573  [8.773056030273438, 8.027151107788086, 7.99886...   \n",
      "18574  [8.790742874145508, 7.838321685791016, 7.64812...   \n",
      "18575  [9.254669189453125, 8.258285522460938, 7.91507...   \n",
      "\n",
      "                                           top6_max_prob  \\\n",
      "0      [0.14530327916145325, 0.14570380747318268, 0.1...   \n",
      "1      [0.14304199814796448, 0.14343959093093872, 0.1...   \n",
      "2      [0.1456489861011505, 0.14712975919246674, 0.14...   \n",
      "3      [0.14231976866722107, 0.14307616651058197, 0.1...   \n",
      "4      [0.14349360764026642, 0.1451214998960495, 0.14...   \n",
      "...                                                  ...   \n",
      "18571  [0.11977476626634598, 0.12072121351957321, 0.1...   \n",
      "18572  [0.12017423659563065, 0.12128829210996628, 0.1...   \n",
      "18573  [0.11955469846725464, 0.1202419176697731, 0.12...   \n",
      "18574  [0.12054113298654556, 0.1220250204205513, 0.12...   \n",
      "18575  [0.11945189535617828, 0.12037839740514755, 0.1...   \n",
      "\n",
      "                                        top6_min_logprob  \\\n",
      "0      [1.9289321899414062, 1.9261794090270996, 1.917...   \n",
      "1      [1.9446169137954712, 1.9418412446975708, 1.932...   \n",
      "2      [1.9265557527542114, 1.9164403676986694, 1.910...   \n",
      "3      [1.949678897857666, 1.944378137588501, 1.92671...   \n",
      "4      [1.9414647817611694, 1.9301838874816895, 1.929...   \n",
      "...                                                  ...   \n",
      "18571  [2.1221423149108887, 2.114271402359009, 2.1129...   \n",
      "18572  [2.1188125610351562, 2.1095850467681885, 2.106...   \n",
      "18573  [2.123981237411499, 2.1182496547698975, 2.1116...   \n",
      "18574  [2.1157641410827637, 2.103529214859009, 2.1025...   \n",
      "18575  [2.1248414516448975, 2.1171152591705322, 2.112...   \n",
      "\n",
      "                                        top6_max_entropy  \n",
      "0      [2.766728401184082, 2.7659854888916016, 2.7641...  \n",
      "1      [2.767561197280884, 2.7662737369537354, 2.7626...  \n",
      "2      [2.765036106109619, 2.7619707584381104, 2.7610...  \n",
      "3      [2.781283378601074, 2.7787840366363525, 2.7786...  \n",
      "4      [2.7659478187561035, 2.7637124061584473, 2.763...  \n",
      "...                                                  ...  \n",
      "18571  [3.845726728439331, 3.8439528942108154, 3.8392...  \n",
      "18572  [3.842477321624756, 3.8417458534240723, 3.8414...  \n",
      "18573  [3.8453803062438965, 3.8448445796966553, 3.844...  \n",
      "18574  [3.844127655029297, 3.8410377502441406, 3.8410...  \n",
      "18575  [3.8407506942749023, 3.8347015380859375, 3.834...  \n",
      "\n",
      "[18576 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "predict_results = anomaly_detector.predict(test_features)\n",
    "print (predict_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
